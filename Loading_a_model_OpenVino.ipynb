{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loading a model - OpenVino.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnUEwvbvE2ek",
        "colab_type": "text"
      },
      "source": [
        "Download from https://software.intel.com/en-us/openvino-toolkit/choose-download/free-download-linux\n",
        "\n",
        "Installation guide\n",
        "https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_linux.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGOw4ywhFIA3",
        "colab_type": "text"
      },
      "source": [
        "After downloading go to Model downloader to download the model\n",
        "\n",
        "\n",
        "/opt/intel/openvino/deployment_tools/tools/model_downloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgq4vI-iHHDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python_version = 3.5\n",
        "[setupvars.sh] OpenVINO environment initialized\n",
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# ls\n",
        "common.py  converter.py  downloader.py  info_dumper.py  license.txt  pytorch_to_onnx.py  README.md  requirements.in  requirements-pytorch.in\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ-T2SRPII9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(venv) root@009324a8b4cb:/home/workspace/intel/human-pose-estimation-0001/INT8# cd /opt/intel/openvino/deployment_tools/tools/model_downloader\n",
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# ls\n",
        "common.py  converter.py  downloader.py  info_dumper.py  license.txt  pytorch_to_onnx.py  README.md  requirements.in  requirements-pytorch.in\n",
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# ./downloader.py --name vehicle-license-plate-detection-barrier-0106 -o /home/workspace\n",
        "################|| Downloading models ||################\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106.xml\n",
        "... 100%, 97 KB, 1412 KB/s, 0 seconds passed\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106.bin\n",
        "... 100%, 2512 KB, 10813 KB/s, 0 seconds passed\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106.xml\n",
        "... 100%, 97 KB, 1905 KB/s, 0 seconds passed\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106.bin\n",
        "... 100%, 1256 KB, 30074 KB/s, 0 seconds passed\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/INT8/vehicle-license-plate-detection-barrier-0106.xml\n",
        "... 100%, 872 KB, 4958 KB/s, 0 seconds passed\n",
        "\n",
        "========== Downloading /home/workspace/intel/vehicle-license-plate-detection-barrier-0106/INT8/vehicle-license-plate-detection-barrier-0106.bin\n",
        "... 100%, 2513 KB, 50840 KB/s, 0 seconds passed\n",
        "\n",
        "################|| Post-processing ||################\n",
        "\n",
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVzYsVKAGIkn",
        "colab_type": "text"
      },
      "source": [
        "./downloader.py --name text-detection-0003 --precisions FP16 -o /home/workspace\n",
        "\n",
        "./downloader.py --name vehicle-attributes-recognition-barrier-0039 --precisions INT8 -o /home/workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_seAJ0T8HlrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# cd /home/workspace\n",
        "(venv) root@009324a8b4cb:/home/workspace# ls\n",
        "Guide.ipynb  intel  README.md  solution\n",
        "(venv) root@009324a8b4cb:/home/workspace# cd intel\n",
        "(venv) root@009324a8b4cb:/home/workspace/intel# ls\n",
        "human-pose-estimation-0001  text-detection-0003  vehicle-attributes-recognition-barrier-0039\n",
        "\n",
        "(venv) root@009324a8b4cb:/home/workspace/intel# cd human-pose-estimation-0001\n",
        "(venv) root@009324a8b4cb:/home/workspace/intel/human-pose-estimation-0001# ls\n",
        "FP16  FP32  INT8\n",
        "(venv) root@009324a8b4cb:/home/workspace/intel/human-pose-estimation-0001# cd INT8\n",
        "(venv) root@009324a8b4cb:/home/workspace/intel/human-pose-estimation-0001/INT8# ls\n",
        "human-pose-estimation-0001.bin  human-pose-estimation-0001.xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiTaIwTpGR7L",
        "colab_type": "text"
      },
      "source": [
        "Configure the Model Optimizer\n",
        "The Model Optimizer is a Python*-based command line tool for importing trained models from popular deep learning frameworks such as Caffe*, TensorFlow*, Apache MXNet*, ONNX* and Kaldi*.\n",
        "\n",
        "- cannot perform inference on trained model without running the model through the Model Optimizer. When you run a pre-trained model through the Model Optimizer, \n",
        "- output is an Intermediate Representation (IR) of the network. \n",
        "\n",
        "\n",
        "The Intermediate Representation is a pair of files that describe the whole model:\n",
        "    - .xml: Describes the network topology\n",
        "    - .bin: Contains the weights and biases binary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMXqXS0LG5Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# ./downloader.py -h \n",
        "usage: downloader.py [-h] [-c CONFIG.YML] [--name PAT[,PAT...]] [--list FILE.LST] [--all] [--print_all] [--precisions PREC[,PREC...]] [-o DIR] [--cache_dir DIR] [--num_attempts N] [--progress_format {text,json}]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  -c CONFIG.YML, --config CONFIG.YML\n",
        "                        model configuration file (deprecated)\n",
        "  --name PAT[,PAT...]   download only models whose names match at least one of the specified patterns\n",
        "  --list FILE.LST       download only models whose names match at least one of the patterns in the specified file\n",
        "  --all                 download all available models\n",
        "  --print_all           print all available models\n",
        "  --precisions PREC[,PREC...]\n",
        "                        download only models with the specified precisions (actual for DLDT networks)\n",
        "  -o DIR, --output_dir DIR\n",
        "                        path where to save models\n",
        "  --cache_dir DIR       directory to use as a cache for downloaded files\n",
        "  --num_attempts N      attempt each download up to N times\n",
        "  --progress_format {text,json}\n",
        "                        which format to use for progress reporting\n",
        "(venv) root@009324a8b4cb:/opt/intel/openvino/deployment_tools/tools/model_downloader# "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}